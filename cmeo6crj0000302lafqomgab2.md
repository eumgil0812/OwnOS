---
title: "Synchronization"
datePublished: Sat Aug 23 2025 11:27:04 GMT+0000 (Coordinated Universal Time)
cuid: cmeo6crj0000302lafqomgab2
slug: synchronization
tags: cuda

---

## 1\. Synchronization

Since a GPU executes thousands of threads simultaneously, **synchronization is essential** to ensure data consistency and to control execution order. CUDA provides synchronization mechanisms at various levels.

### (a) Synchronization Functions

**‚ë† Block-level synchronization**

* `__syncthreads()`
    
* All threads within the same block must reach this point before proceeding.
    
* Essential for cooperative computations using shared memory (e.g., tiled matrix multiplication).
    
* Does not affect threads outside the block.
    

**‚ë° Warp-level synchronization**

* `__syncwarp(mask)`
    
* Synchronizes threads within the same warp (32 threads).
    
* Useful when you want to synchronize only a subset of threads, not the entire block.
    
* On modern architectures, explicit warp sync may be required after warp divergence.
    

**‚ë¢ Grid (kernel)-level synchronization**

* It is **not possible to synchronize across blocks within a single kernel**.
    
* For grid-level synchronization, the kernel must be spl
    
    * ex) `kernel1<<<...>>>(); cudaDeviceSynchronize(); kernel2<<<...>>>();`
        
* Cooperative Groups provide grid-level synchronization, but with certain limitations.
    

---

### (b) Atomic Functions

* Used to prevent data races when multiple threads update the same memory location simultaneously.
    
* Examples: `atomicAdd()`, `atomicSub()`, `atomicMax()`, etc.
    
* Atomic operations serialize access and can reduce performance.
    
* However, they are safer than race conditions caused by unsynchronized access.
    

---

### (c) Manual Control

Sometimes, explicit synchronization from the **CPU side** is required:

* `cudaDeviceSynchronize()` ‚Üí blocks the CPU until **all GPU work** is finished.
    
* `cudaStreamSynchronize(stream)` ‚Üí blocks the CPU until the specified **stream** finishes.
    

These are useful when mixing multiple kernels/streams and enforcing a specific order of execution.

---

### (d) Things to Watch Out For

* **Excessive synchronization causes performance loss** ‚Üí minimize when possible.
    
* **Improper block sync** ‚Üí threads outside a block must not call `__syncthreads()` (deadlock risk).
    
* **Atomic operations may become bottlenecks** ‚Üí avoid using them across very large arrays.
    
* **Memory visibility** ‚Üí without synchronization, writes to shared/global memory may not be visible to other threads in time.
    

## 2\. CUDA Streams and Concurrent Execution

### 1) Definition and Characteristics of CUDA Streams

* A **CUDA stream** is a **queue** that defines the order of GPU operations (kernel launches, memory copies, etc.).
    

**Characteristics**:

* Within the **same stream**, operations are executed sequentially in the order they were issued.
    
* Across **different streams**, operations can run concurrently (in parallel).
    
* By default, all CUDA calls go into the **default stream (stream 0)**.
    

üëâ Using streams enables advanced optimizations such as overlapping **computation and data transfer**, and running **multiple kernels concurrently**.

### (a) Creating and Destroying Non-NULL Streams

* **Non-NULL streams** are streams explicitly created by the programmer (unlike the default stream, which is implicitly provided).
    
* They allow you to manage multiple independent execution queues on the GPU.
    

### (b) Specifying a Stream When Launching Kernels

```cpp
kernel<<<gridDim, blockDim, 0, stream>>>(args...);
```

The last parameter in the kernel launch configuration is the stream.

```cpp
myKernel<<<grid, block, 0, stream1>>>(dA, dB, dC);
myKernel<<<grid, block, 0, stream2>>>(dX, dY, dZ);
```

* you want me to also add a **timeline-style example** (like ‚ÄúStream1: H2D ‚Üí Kernel ‚Üí D2H‚Äù overlapping with ‚ÄúStream2‚Äù)?
    
* That could make this clearer for beginners.
    

### 2) Concurrent Execution of CUDA Operations

To fully utilize the GPU, it‚Äôs important to **overlap computation (kernel execution) with data transfers (Host ‚Üî Device copies)**.  
The key concepts here are **asynchronous memory copies** and **pinned memory**.

---

### (a) Asynchronous Memory Copy and Pinned Memory

* **Synchronous copy (**`cudaMemcpy`)  
    ‚Üí The CPU must **wait until the copy is finished** before continuing.
    
* **Asynchronous copy (**`cudaMemcpyAsync`)  
    ‚Üí The CPU can **issue the copy request and immediately move on**.  
    ‚Üí This allows memory transfers and GPU kernel execution to happen **at the same time**.
    

‚ö†Ô∏è **Important condition:** The host memory must be **pinned (page-locked)** for true asynchronous transfers.

---

### Why is pinned memory necessary?

* **Pageable memory (default)** ‚Üí the OS can move it around in RAM at any time.
    
    * The GPU cannot directly access it with DMA.
        
    * CUDA has to use a hidden **staging buffer**, adding overhead ‚Üí slower and effectively synchronous.
        
* **Pinned memory (page-locked)** ‚Üí fixed in physical RAM, cannot be moved by the OS.
    
    * The GPU can directly access it using DMA.
        
    * This makes transfers **faster** and allows **true asynchronous overlap** with kernels.
        

---

üëâ **Summary:**  
To use asynchronous copies effectively, you **must use pinned memory**.

---

### (b) Allocating and Freeing Pinned Memory

CUDA makes it very simple to work with pinned memory:

```cpp
float* hA;
cudaMallocHost((void**)&hA, size * sizeof(float)); // ÌïÄÎìú Î©îÎ™®Î¶¨ Ìï†Îãπ
// ... hAÎ•º CPU Î∞∞Ïó¥Ï≤òÎüº ÏÇ¨Ïö© Í∞ÄÎä• ...
cudaFreeHost(hA); // Ìï¥Ï†ú
```

* `cudaMallocHost` ‚Üí allocates pinned memory (page-locked), which the GPU can access directly.
    
* `cudaFreeHost` ‚Üí frees the pinned memory.
    

### 3) Stream Synchronization

CUDA streams are **asynchronous by default**.  
This means when the CPU launches a kernel or a memory copy into a stream, it immediately moves on to the **next line of code**, while the GPU continues execution in the background.

üëâ However, sometimes you need control, such as:

* ‚ÄúThis kernel must finish before the next one starts.‚Äù
    
* ‚ÄúThe CPU must wait for the GPU result before proceeding.‚Äù
    

In these cases, you use **synchronization**.

‚ë† Synchronizing a Specific Stream

```cpp
cudaStreamSynchronize(stream);
```

* The CPU will **wait until all operations in the specified stream are finished**.
    
* Example: when a kernel in `stream1` must complete before the CPU reads back its results.
    

‚ë° Event-based Synchronization

```cpp
cudaEvent_t event;
cudaEventCreate(&event);

cudaEventRecord(event, stream1);
cudaStreamWaitEvent(stream2, event, 0); // stream2Îäî eventÍπåÏßÄ Í∏∞Îã§Î¶º
```

* `stream1` records an event.
    
* `stream2` will not start until the event has fired.
    
    üëâ This creates **ordering dependencies between streams** without forcing a global device-wide sync.
    

‚ë¢ Device-wide Synchronization

```cpp
cudaDeviceSynchronize();
```

* The CPU waits until **all streams and all GPU work** are finished.
    
* Very powerful but costly ‚Äî it stalls the entire GPU, so it should only be used when absolutely necessary.
    

## Example: Asynchronous Copy + Kernel Execution with Two Streams and Synchronization

**Key points**

* Use `cudaMallocHost` to allocate **pinned (page-locked) memory** ‚Üí required for `cudaMemcpyAsync` to work as truly asynchronous.
    
* Create **two streams** and alternate between them like **double-buffering**.
    
* Use `cudaEventRecord` / `cudaStreamWaitEvent` to enforce the correct order of **copy ‚Üí kernel ‚Üí copy** inside each stream.
    
* Compare performance:
    
    * **(A) Single stream (sequential)** vs.
        
    * **(B) Dual streams (overlapped execution)** ‚Üí measure time difference.
        

```cpp
// stream_overlap_demo.cu
#include <cstdio>
#include <cstdlib>
#include <cuda_runtime.h>

#define CHECK(call) do { \
    cudaError_t _e = (call); \
    if (_e != cudaSuccess) { \
        fprintf(stderr, "CUDA error %s:%d: %s\n", __FILE__, __LINE__, cudaGetErrorString(_e)); \
        std::exit(EXIT_FAILURE); \
    } \
} while(0)

__global__ void vecAdd(const float* __restrict__ A,
                       const float* __restrict__ B,
                       float* __restrict__ C,
                       int n)
{
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < n) C[i] = A[i] + B[i];
}

static void initArray(float* p, int n, float v) {
    for (int i = 0; i < n; ++i) p[i] = v;
}

int main(int argc, char** argv) {
    // Ï†ÑÏ≤¥ ÏõêÏÜå Ïàò (Í∏∞Î≥∏: 4M)
    int N = (argc > 1) ? std::atoi(argv[1]) : (1 << 22); // 4,194,304
    // Ï≤≠ÌÅ¨ ÌÅ¨Í∏∞ (Í∏∞Î≥∏: 1M)
    int CHUNK = (argc > 2) ? std::atoi(argv[2]) : (1 << 20);

    if (CHUNK > N) CHUNK = N;
    int numChunks = (N + CHUNK - 1) / CHUNK;

    size_t bytesAll = size_t(N) * sizeof(float);
    size_t bytesChunk = size_t(CHUNK) * sizeof(float);
    printf("N=%d (%.2f MB/array), CHUNK=%d (%.2f MB)\n",
           N, bytesAll / (1024.0*1024.0), CHUNK, bytesChunk / (1024.0*1024.0));

    // ÌïÄÎìú(ÌéòÏù¥ÏßÄ Ïû†Í∏à) Ìò∏Ïä§Ìä∏ Î©îÎ™®Î¶¨
    float *hA, *hB, *hC;
    CHECK(cudaMallocHost(&hA, bytesAll));
    CHECK(cudaMallocHost(&hB, bytesAll));
    CHECK(cudaMallocHost(&hC, bytesAll));
    initArray(hA, N, 1.0f);
    initArray(hB, N, 2.0f);

    // ÎîîÎ∞îÏù¥Ïä§ Î≤ÑÌçº 2ÏÑ∏Ìä∏ (ÎçîÎ∏îÎ≤ÑÌçºÎßÅÏ≤òÎüº)
    float *dA[2], *dB[2], *dC[2];
    for (int s = 0; s < 2; ++s) {
        CHECK(cudaMalloc(&dA[s], bytesChunk));
        CHECK(cudaMalloc(&dB[s], bytesChunk));
        CHECK(cudaMalloc(&dC[s], bytesChunk));
    }

    // Ïä§Ìä∏Î¶º 2Í∞ú
    cudaStream_t stream[2];
    CHECK(cudaStreamCreate(&stream[0]));
    CHECK(cudaStreamCreate(&stream[1]));

    // Ïù¥Î≤§Ìä∏: Î≥µÏÇ¨ ÏôÑÎ£å/Ïª§ÎÑê ÏôÑÎ£å Îì±ÏùÑ Ïä§Ìä∏Î¶º ÎÇ¥Î∂Ä ÏàúÏÑú Ï†úÏñ¥Ïóê ÏÇ¨Ïö©(ÌïÑÏàòÎäî ÏïÑÎãò, ÌïôÏäµÏö©)
    cudaEvent_t h2dDone[2], kernelDone[2];
    for (int s = 0; s < 2; ++s) {
        CHECK(cudaEventCreate(&h2dDone[s]));
        CHECK(cudaEventCreate(&kernelDone[s]));
    }

    dim3 block(256);
    // (Ï≤≠ÌÅ¨ Îã®ÏúÑ Í∑∏Î¶¨Îìú ÌÅ¨Í∏∞Îäî Îß§ Î∞òÎ≥µÏóêÏÑú Í≥ÑÏÇ∞)

    // ------------------------------
    // (A) Îã®Ïùº Ïä§Ìä∏Î¶º ÏßÅÎ†¨ ÌååÏù¥ÌîÑÎùºÏù∏
    // ------------------------------
    cudaStream_t serial;
    CHECK(cudaStreamCreate(&serial));

    cudaEvent_t tA_start, tA_stop;
    CHECK(cudaEventCreate(&tA_start));
    CHECK(cudaEventCreate(&tA_stop));

    CHECK(cudaEventRecord(tA_start, serial));
    for (int c = 0; c < numChunks; ++c) {
        int off = c * CHUNK;
        int count = (c == numChunks - 1) ? (N - off) : CHUNK;
        size_t bytes = size_t(count) * sizeof(float);
        int grid = (count + block.x - 1) / block.x;

        // H2D (ÎèôÍ∏∞/ÎπÑÎèôÍ∏∞ ÏÉÅÍ¥ÄÏóÜÏù¥ Í∞ôÏùÄ Ïä§Ìä∏Î¶ºÏóêÏÑ† ÏàúÏ∞®)
        CHECK(cudaMemcpyAsync(dA[0], hA + off, bytes, cudaMemcpyHostToDevice, serial));
        CHECK(cudaMemcpyAsync(dB[0], hB + off, bytes, cudaMemcpyHostToDevice, serial));

        // Kernel
        vecAdd<<<grid, block, 0, serial>>>(dA[0], dB[0], dC[0], count);

        // D2H
        CHECK(cudaMemcpyAsync(hC + off, dC[0], bytes, cudaMemcpyDeviceToHost, serial));
    }
    CHECK(cudaEventRecord(tA_stop, serial));
    CHECK(cudaEventSynchronize(tA_stop));
    float msA = 0.f;
    CHECK(cudaEventElapsedTime(&msA, tA_start, tA_stop));
    CHECK(cudaStreamDestroy(serial));
    CHECK(cudaEventDestroy(tA_start));
    CHECK(cudaEventDestroy(tA_stop));

    // ------------------------------
    // (B) Ïù¥Ï§ë Ïä§Ìä∏Î¶º Í≤πÏπ® ÌååÏù¥ÌîÑÎùºÏù∏
    // ------------------------------
    cudaEvent_t tB_start, tB_stop;
    CHECK(cudaEventCreate(&tB_start));
    CHECK(cudaEventCreate(&tB_stop));

    CHECK(cudaEventRecord(tB_start, 0));
    for (int c = 0; c < numChunks; ++c) {
        int s = c & 1;         // 0,1,0,1...
        int off = c * CHUNK;
        int count = (c == numChunks - 1) ? (N - off) : CHUNK;
        size_t bytes = size_t(count) * sizeof(float);
        int grid = (count + block.x - 1) / block.x;

        // 1) H2D (A,B)
        CHECK(cudaMemcpyAsync(dA[s], hA + off, bytes, cudaMemcpyHostToDevice, stream[s]));
        CHECK(cudaMemcpyAsync(dB[s], hB + off, bytes, cudaMemcpyHostToDevice, stream[s]));
        // H2D ÏôÑÎ£å ÏãúÏ†ê ÌëúÏãú
        CHECK(cudaEventRecord(h2dDone[s], stream[s]));

        // 2) Ïª§ÎÑêÏùÄ H2D ÏôÑÎ£å ÌõÑÏóêÎßå Ïã§Ìñâ
        CHECK(cudaStreamWaitEvent(stream[s], h2dDone[s], 0));
        vecAdd<<<grid, block, 0, stream[s]>>>(dA[s], dB[s], dC[s], count);
        CHECK(cudaEventRecord(kernelDone[s], stream[s]));

        // 3) D2HÎäî Ïª§ÎÑê ÏôÑÎ£å ÌõÑÏóêÎßå Ïã§Ìñâ
        CHECK(cudaStreamWaitEvent(stream[s], kernelDone[s], 0));
        CHECK(cudaMemcpyAsync(hC + off, dC[s], bytes, cudaMemcpyDeviceToHost, stream[s]));
        // Îã§Ïùå Î∞òÎ≥µÏóêÏÑú Í∞ôÏùÄ s Î≤ÑÌçºÎ•º Ïû¨ÏÇ¨Ïö©ÌïòÍ∏∞ Ï†ÑÏóê, Ïù¥ Ïä§Ìä∏Î¶ºÏù¥ ÎÅùÎÇ¨ÎäîÏßÄ Î≥¥Ïû•ÌïòÎ†§Î©¥
        // Î£®ÌîÑ ÏÉÅÎã®ÏóêÏÑú waitÎ•º Îçî Îëò ÏàòÎèÑ ÏûàÏßÄÎßå, Ïó¨Í∏∞ÏÑ† Ïù¥Î≤§Ìä∏ Ï≤¥Ïù∏ÏúºÎ°ú Ï∂©Î∂Ñ.
    }

    // Îëê Ïä§Ìä∏Î¶ºÏùò Î™®Îì† ÏûëÏóÖ ÏôÑÎ£å ÎåÄÍ∏∞
    CHECK(cudaStreamSynchronize(stream[0]));
    CHECK(cudaStreamSynchronize(stream[1]));
    CHECK(cudaEventRecord(tB_stop, 0));
    CHECK(cudaEventSynchronize(tB_stop));
    float msB = 0.f;
    CHECK(cudaEventElapsedTime(&msB, tB_start, tB_stop));

    // Í≤∞Í≥º Í≤ÄÏÇ¨(Í∞ÑÎã®)
    bool ok = true;
    for (int i = 0; i < 10; ++i) {
        if (hC[i] != 3.0f) { ok = false; break; }
    }
    printf("Result check: %s\n", ok ? "OK" : "FAIL");

    // ÏÑ±Îä• ÏöîÏïΩ
    double GB = (3.0 * bytesAll) / (1024.0 * 1024.0 * 1024.0); // A,B ÏùΩÍ∏∞ + C Ïì∞Í∏∞(Í∞úÎÖêÏÉÅ)
    printf("[A] Single stream:   %8.3f ms,  Effective BW ~ %6.2f GB/s\n", msA, GB / (msA/1000.0));
    printf("[B] Dual streams:    %8.3f ms,  Effective BW ~ %6.2f GB/s\n", msB, GB / (msB/1000.0));
    printf("Speedup (A/B): %.2fx\n", msA / msB);

    // Ï†ïÎ¶¨
    for (int s = 0; s < 2; ++s) {
        CHECK(cudaFree(dA[s]));
        CHECK(cudaFree(dB[s]));
        CHECK(cudaFree(dC[s]));
        CHECK(cudaStreamDestroy(stream[s]));
        CHECK(cudaEventDestroy(h2dDone[s]));
        CHECK(cudaEventDestroy(kernelDone[s]));
    }
    CHECK(cudaFreeHost(hA));
    CHECK(cudaFreeHost(hB));
    CHECK(cudaFreeHost(hC));
    CHECK(cudaEventDestroy(tB_start));
    CHECK(cudaEventDestroy(tB_stop));
    return 0;
}
```